<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Image Classification with Convolutional Neural Networks: Build a Convolutional Neural Network</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="manifest" href="../site.webmanifest"><link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../03-build-cnn.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Image Classification with Convolutional Neural Networks
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Image Classification with Convolutional Neural Networks
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled><input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset></form>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Image Classification with Convolutional Neural Networks
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 40%" class="percentage">
    40%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 40%" aria-valuenow="40" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../03-build-cnn.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->
      
            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="setup-gpu.html">1. Setup - GPU</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="01-introduction.html">2. Introduction to Deep Learning</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="02-image-data.html">3. Introduction to Image Data</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        4. Build a Convolutional Neural Network
        </span>
      </button>
    </div><!--/div.accordion-header-->
        
    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#neural-networks">Neural Networks</a></li>
<li><a href="#convolutional-neural-networks">Convolutional Neural Networks</a></li>
<li><a href="#putting-it-all-together">Putting it all together</a></li>
<li><a href="#we-have-a-model-now-what">We have a model now what?</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="04-fit-cnn.html">5. Compile and Train (Fit) a Convolutional Neural Network</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="05-evaluate-predict-cnn.html">6. Evaluate a Convolutional Neural Network and Make Predictions (Classifications)</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="06-conclusion.html">7. Conclusion</a>
    </div><!--/div.accordion-header-->
        
  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">
            
            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/02-image-data.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/04-fit-cnn.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/02-image-data.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Introduction to
        </a>
        <a class="chapter-link float-end" href="../instructor/04-fit-cnn.html" rel="next">
          Next: Compile and Train... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Build a Convolutional Neural Network</h1>
        <p>Last updated on 2024-02-25 |
        
        <a href="https://https://github.com/erinmgraham/icwithcnn/edit/main/episodes/03-build-cnn.html" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
        
        
        
        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
        
        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What is a (artificial) neural network (ANN)?</li>
<li>How is a convolutional neural network (CNN) different from an
ANN?</li>
<li>What are the types of layers used to build a CNN?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Understand how a convolutional neural network (CNN) differs from an
artificial neural network (ANN).</li>
<li>Explain the terms: kernel, filter.</li>
<li>Know the different layers: convolutional, pooling, flatten,
dense.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section id="neural-networks"><h2 class="section-heading">Neural Networks<a class="anchor" aria-label="anchor" href="#neural-networks"></a>
</h2>
<hr class="half-width"><p>A <strong>neural network</strong> is an artificial intelligence
technique loosely based on the way neurons in the brain work.</p>
<div class="section level3">
<h3 id="a-single-nueron">A single nueron<a class="anchor" aria-label="anchor" href="#a-single-nueron"></a></h3>
<p>A neural network consists of connected computational units called
<strong>neurons</strong>. Each neuron will:</p>
<ul><li>Take one or more inputs (<span class="math inline">\(x_1, x_2,
...\)</span>), e.g., input data expressed as floating point
numbers.</li>
<li>Conduct three main operations most of the time:
<ul><li>Calculate the weighted sum of the inputs where ($w_1, w_2, … $)
indicate weights</li>
<li>Add an extra constant weight (i.e. a bias term) to this weighted
sum</li>
<li>Apply a non-linear function to the output so far (using a predefined
activation function such as the ReLU function)</li>
</ul></li>
<li>Return one output value, again a floating point number.</li>
</ul><p>One example equation to calculate the output for a neuron is: <span class="math inline">\(output=ReLU(∑i(xi∗wi)+bias)\)</span></p>
<figure><img src="../fig/03_neuron.png" alt="diagram of a single neuron taking multiple inputs and their associated weights in and then applying an activation function to predict a single output" class="figure mx-auto d-block"></figure></div>
<div class="section level3">
<h3 id="combining-multiple-neurons-into-a-network">Combining multiple neurons into a network<a class="anchor" aria-label="anchor" href="#combining-multiple-neurons-into-a-network"></a></h3>
<p>Multiple neurons can be joined together by connecting the output of
one to the input of another. These connections are associated with
weights that determine the ‘strength’ of the connection, and the weights
are adjusted during training. In this way, the combination of neurons
and connections describe a computational graph, an example can be seen
in the image below.</p>
<p>In most neural networks neurons are aggregated into layers. Signals
travel from the input layer to the output layer, possibly through one or
more intermediate layers called hidden layers. The image below
illustrates an example of a neural network with three layers, each
circle is a neuron, each line is an edge and the arrows indicate the
direction data moves in.</p>
<figure><img src="../fig/03_neural_net.png" alt="diagram of a neural with four neurons taking multiple inputs and their weights and predicting multiple outputs" class="figure mx-auto d-block"><div class="figcaption">The image above is by Glosser.ca, <a href="https://creativecommons.org/licenses/by-sa/3.0" class="external-link">CC BY-SA 3.0</a>,
via Wikimedia Commons, <a href="https://commons.wikimedia.org/wiki/File:Colored_neural_network.svg" class="external-link">original
source</a>
</div>
</figure><p>Neural networks aren’t a new technique, they have been around since
the late 1940s. But until around 2010 neural networks tended to be quite
small, consisting of only 10s or perhaps 100s of neurons. This limited
them to only solving quite basic problems. Around 2010 improvements in
computing power and the algorithms for training the networks made much
larger and more powerful networks practical. These are known as deep
neural networks or Deep Learning.</p>
</div>
</section><section id="convolutional-neural-networks"><h2 class="section-heading">Convolutional Neural Networks<a class="anchor" aria-label="anchor" href="#convolutional-neural-networks"></a>
</h2>
<hr class="half-width"><p>A convolutional neural network (CNN) is a type of artificial neural
network (ANN) most commonly applied to analyze visual imagery. They are
designed to recognize the spatial structure of images when extracting
features.</p>
<div class="section level3">
<h3 id="step-4--build-an-architecture-from-scratch-or-choose-a-pretrained-model">Step 4. Build an architecture from scratch or choose a pretrained
model<a class="anchor" aria-label="anchor" href="#step-4--build-an-architecture-from-scratch-or-choose-a-pretrained-model"></a></h3>
<p>Let us explore how to build a neural network from scratch. Although
this sounds like a daunting task, with Keras it is surprisingly
straightforward. With Keras you compose a neural network by creating
layers and linking them together.</p>
<p>This is the same network from the introduction:</p>
<pre><code><span><span class="co"># # CNN Part 1</span></span>
<span><span class="co"># # Input layer of 32x32 images with three channels (RGB)</span></span>
<span><span class="co"># inputs_intro = keras.Input(shape=train_images.shape[1:])</span></span>
<span></span>
<span><span class="co"># # CNN Part 2</span></span>
<span><span class="co"># # Convolutional layer with 16 filters, 3x3 kernel size, and ReLU activation</span></span>
<span><span class="co"># x_intro = keras.layers.Conv2D(16, (3, 3), activation='relu')(inputs_intro)</span></span>
<span><span class="co"># # Pooling layer with input window sized 2,2</span></span>
<span><span class="co"># x_intro = keras.layers.MaxPooling2D((2, 2))(x_intro)</span></span>
<span><span class="co"># # Second Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation</span></span>
<span><span class="co"># x_intro = keras.layers.Conv2D(32, (3, 3), activation='relu')(x_intro)</span></span>
<span><span class="co"># # Second Pooling layer with input window sized 2,2</span></span>
<span><span class="co"># x_intro = keras.layers.MaxPooling2D((2, 2))(x_intro)</span></span>
<span><span class="co"># # Flatten layer to convert 2D feature maps into a 1D vector</span></span>
<span><span class="co"># x_intro = keras.layers.Flatten()(x_intro)</span></span>
<span><span class="co"># # Dense layer with 64 neurons and ReLU activation</span></span>
<span><span class="co"># x_intro = keras.layers.Dense(64, activation='relu')(x_intro)</span></span>
<span></span>
<span><span class="co"># # CNN Part 3</span></span>
<span><span class="co"># # Output layer with 10 units (one for each class) and softmax activation</span></span>
<span><span class="co"># outputs_intro = keras.layers.Dense(10, activation='softmax')(x_intro)</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="parts-of-a-neural-network">Parts of a neural network<a class="anchor" aria-label="anchor" href="#parts-of-a-neural-network"></a></h3>
<p>There are three main components of a neural network:</p>
<ul><li>CNN Part 1. Input Layer</li>
<li>CNN Part 2. Hidden Layers</li>
<li>CNN Part 3. Output Layer</li>
</ul><p>The output from each layer becomes the input to the next layer.</p>
<div class="section level4">
<h4 id="cnn-part-1--input-layer">CNN Part 1. Input Layer<a class="anchor" aria-label="anchor" href="#cnn-part-1--input-layer"></a></h4>
<p>The Input in Keras gets special treatment when images are used. Keras
automatically calculates the number of inputs and outputs a specific
layer needs and therefore how many edges need to be created. This means
we must let Keras know how big our input is going to be. We do this by
instantiating a <code>keras.Input</code> class and pass it a tuple to
indicate the dimensionality of the input data.</p>
<p>In our case, the shape of an image is defined by its pixel dimensions
and number of channels:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># recall the shape of the images in our dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="bu">print</span>(train_images.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(40000, 32, 32, 3) # number of images, image width in pixels, image height in pixels, number of channels (RGB)</code></pre>
</div>
<p>The input layer is created with the <code>tf.keras.Input</code>
function and its first parameter is the expected shape of the input.</p>
<p>Because the shape of our input dataset includes the total number of
images, we want to take a slice of the shape related to an individual
image, hence:</p>
<pre><code><span><span class="co"># Input layer of 32x32 images with three channels (RGB)</span></span>
<span><span class="co">#inputs_intro = keras.Input(shape=train_images.shape[1:])</span></span></code></pre>
</div>
<div class="section level4">
<h4 id="cnn-part-2--hidden-layers">CNN Part 2. Hidden Layers<a class="anchor" aria-label="anchor" href="#cnn-part-2--hidden-layers"></a></h4>
<p>The next component consists of the so-called hidden layers of the
network. The reason they are referred to as hidden is because the true
values of their nodes are unknown.</p>
<p>In a CNN, the hidden layers typically consist of convolutional,
pooling, reshaping (e.g., Flatten), and dense layers.</p>
<p>Check out the <a href="https://keras.io/api/layers/" class="external-link">Layers API</a>
section of the Keras documentation for each layer type and its
parameters.</p>
<div class="section level5">
<h5 id="convolutional-layers"><strong>Convolutional Layers</strong><a class="anchor" aria-label="anchor" href="#convolutional-layers"></a></h5>
<p>A <strong>convolutional</strong> layer is a fundamental building
block in a CNN designed for processing structured grid data, such as
images. It applies convolution operations to input data using learnable
filters or kernels, extracting local patterns and features (e.g. edges,
corners). These filters enable the network to capture hierarchical
representations of visual information, allowing for effective feature
learning.</p>
<p>To find the particular features of an image, CNNs make use of a
concept from image processing that precedes Deep Learning.</p>
<p>A <strong>convolution matrix</strong>, or <strong>kernel</strong>, is
a matrix transformation that we ‘slide’ over the image to calculate
features at each position of the image. For each pixel, we calculate the
matrix product between the kernel and the pixel with its surroundings.
Here is one example of a 3x3 kernel used to detect edges:</p>
<pre><code>[[-1, -1, -1],
 [0,   0,  0]
 [1,   1,  1]]</code></pre>
<p>This kernel will give a high value to a pixel if it is on a
horizontal border between dark and light areas.</p>
<p>In the following image, the effect of such a kernel on the values of
a single-channel image stands out. The red cell in the output matrix is
the result of multiplying and summing the values of the red square in
the input, and the kernel. Applying this kernel to a real image
demonstrates it does indeed detect horizontal edges.</p>
<figure><img src="../fig/03_conv_matrix.png" alt="6x5 input matrix representing a single colour channel image being multipled by a 3x3 kernel to produce a 4x4 output matrix to detect horizonal edges in an image " class="figure mx-auto d-block"></figure><figure><img src="../fig/03_conv_image.png" alt="single colour channel image of a cat multiplied by a 3x3 kernel to produce an image of a cat where the edges  stand out" class="figure mx-auto d-block"></figure><p>There are several types of convolutional layers available in Keras
depending on your application. We use the two-dimensional layer
typically used for images, <code>tf.keras.layers.Conv2D</code>.</p>
<p>We define arguments for the number of filters, the kernel size, and
the activation function.</p>
<pre><code><span><span class="co"># # Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation</span></span>
<span><span class="co"># x_intro = keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs_intro)</span></span></code></pre>
<p>The instantiation here has three parameters and a seemingly strange
combination of parentheses, so let us break it down.</p>
<ul><li>The first parameter is the number of filters in this layer. This is
one of the hyperparameters of our system and should be chosen carefully.
<ul><li>Good practice is to start with a relatively small number of filters
in the first layer to prevent overfitting.</li>
<li>Choosing a number of filters as a power of two (e.g., 32, 64, 128)
is common.</li>
</ul></li>
<li>The second parameter is the kernel size which we already discussed.
Smaller kernels are often used to capture fine-grained features and
odd-sized filters are preferred because they have a centre pixel which
helps maintain spatial symmetry during convolutions.</li>
<li>The third parameter is the activation function to use.
<ul><li>Here we choose <strong>relu</strong> which is one of the most
commonly used in deep neural networks that is proven to work well.</li>
<li>We will discuss activation functions later in <strong>Step 9. Tune
hyperparameters</strong> but to satisfy your curiosity,
<code>ReLU</code> stands for Rectified Linear Unit (ReLU).</li>
</ul></li>
<li>Next is an extra set of parenthenses with inputs in them that means
after an instance of the Conv2D layer is created, it can be called as if
it was a function. This tells the Conv2D layer to connect the layer
passed as a parameter, in this case the inputs.</li>
<li>Finally, we store a reference so we can pass it to the next
layer.</li>
</ul><div id="playing-with-convolutions" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="playing-with-convolutions" class="callout-inner">
<h3 class="callout-title">Playing with convolutions<a class="anchor" aria-label="anchor" href="#playing-with-convolutions"></a>
</h3>
<div class="callout-content">
<p>Convolutions applied to images can be hard to grasp at first.
Fortunately, there are resources out there that enable users to
interactively play around with images and convolutions:</p>
<ul><li><p><a href="https://setosa.io/ev/image-kernels/" class="external-link">Image kernels
explained</a> illustrates how different convolutions can achieve certain
effects on an image, like sharpening and blurring.</p></li>
<li><p>The <a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" class="external-link">convolutional
neural network cheat sheet</a> provides animated examples of the
different components of convolutional neural nets.</p></li>
</ul></div>
</div>
</div>
<div id="challenge-border-pixels" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-border-pixels" class="callout-inner">
<h3 class="callout-title">CHALLENGE Border pixels<a class="anchor" aria-label="anchor" href="#challenge-border-pixels"></a>
</h3>
<div class="callout-content">
<p>What do you think happens to the border pixels when applying a
convolution?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>There are different ways of dealing with border pixels.</p>
<ul><li>You can ignore them, which means your output image is slightly
smaller then your input.</li>
<li>It is also possible to ‘pad’ the borders, e.g., with the same value
or with zeros, so that the convolution can also be applied to the border
pixels. In that case, the output image will have the same size as the
input image.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level5">
<h5 id="pooling-layers"><strong>Pooling Layers</strong><a class="anchor" aria-label="anchor" href="#pooling-layers"></a></h5>
<p>The convolutional layers are often intertwined with
<strong>Pooling</strong> layers. As opposed to the convolutional layer
used in feature extraction, the pooling layer alters the dimensions of
the image and reduces it by a scaling factor effectively decreasing the
resolution of your picture.</p>
<p>The rationale behind this is that higher layers of the network should
focus on higher-level features of the image. By introducing a pooling
layer, the subsequent convolutional layer has a broader ‘view’ on the
original image.</p>
<p>Similar to convolutional layers, Keras offers several pooling layers
and one used for images (2D spatial data) is the
<code>tf.keras.layers.MaxPooling2D</code> class.</p>
<pre><code><span><span class="co"># # Pooling layer with input window sized 2,2</span></span>
<span><span class="co"># x_intro = keras.layers.MaxPooling2D((2, 2))(x_intro)</span></span></code></pre>
<p>The instantiation here has a single parameter, pool_size.</p>
<p>The function downsamples the input along its spatial dimensions
(height and width) by taking the <strong>maximum</strong> value over an
input window (of size defined by pool_size) for each channel of the
input. By taking the maximum instead of the average, the most prominent
features in the window are emphasized.</p>
<p>A 2x2 pooling size reduces the width and height of the input by a
factor of 2. Empirically, a 2x2 pooling size has been found to work well
in various for image classification tasks and also strikes a balance
between down-sampling for computational efficiency and retaining
important spatial information.</p>
</div>
<div class="section level5">
<h5 id="dense-layers"><strong>Dense layers</strong><a class="anchor" aria-label="anchor" href="#dense-layers"></a></h5>
<p>A <strong>dense</strong> layer has a number of neurons, which is a
parameter you choose when you create the layer. When connecting the
layer to its input and output layers every neuron in the dense layer
gets an edge (i.e. connection) to <strong>all</strong> of the input
neurons and <strong>all</strong> of the output neurons.</p>
<figure><img src="../fig/03-neural_network_sketch_dense.png" alt="diagram of a neural network with multiple inputs feeding into to two seperate dense layers with connections between all the inputs and outputs" class="figure mx-auto d-block"></figure><p>This layer is called fully connected, because all input neurons are
taken into account by each output neuron. It aggregates global
information about the features learned in previous layers to make a
decision about the class of the input.</p>
<p>In Keras, a densely-connected layer is defined by the
<code>tf.keras.layers.Dense</code> class.</p>
<pre><code><span><span class="co"># # Dense layer with 64 neurons and ReLU activation</span></span>
<span><span class="co"># x_intro = keras.layers.Dense(64, activation='relu')(x_intro)</span></span></code></pre>
<p>This instantiation has two parameters: the number of neurons and the
activation function.</p>
<p>The choice of how many neurons to specify is often determined through
experimentation and can impact the performance of our CNN. Too few
neurons may not capture complex patterns in the data but too many
neurons may lead to overfitting.</p>
<div id="challenge-number-of-parameters" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-number-of-parameters" class="callout-inner">
<h3 class="callout-title">CHALLENGE Number of parameters<a class="anchor" aria-label="anchor" href="#challenge-number-of-parameters"></a>
</h3>
<div class="callout-content">
<p>Suppose we create a single Dense (fully connected) layer with 100
hidden units that connects to the input pixels. How many parameters does
this layer have?</p>
<ul><li>A. 307200</li>
<li>B. 307300</li>
<li>C. 100</li>
<li>D. 3072</li>
</ul></div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>The correct answer is B.</p>
<p>Each entry of the input dimensions is connected with 100 neurons of
our hidden layer, and each of these neurons has a bias term associated
to it. So we have 307300 parameters to learn.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>width, height <span class="op">=</span> (<span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>n_hidden_neurons <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>n_bias <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>n_input_items <span class="op">=</span> width <span class="op">*</span> height <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>n_parameters <span class="op">=</span> (n_input_items <span class="op">*</span> n_hidden_neurons) <span class="op">+</span> n_bias</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="bu">print</span>(n_parameters)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">307300</span></span></code></pre>
</div>
<p>We can also check this by building the layer in Keras:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>inputs_ex <span class="op">=</span> keras.Input(shape<span class="op">=</span>n_input_items)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>outputs_ex <span class="op">=</span> keras.layers.Dense(<span class="dv">100</span>)(inputs_ex)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>model_ex <span class="op">=</span> keras.models.Model(inputs<span class="op">=</span>inputs_ex, outputs<span class="op">=</span>outputs_ex)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>model_ex.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 3072)]            0
_________________________________________________________________
dense (Dense)                (None, 100)               307300
=================================================================
Total params: 307,300
Trainable params: 307,300
Non-trainable params: 0</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level5">
<h5 id="reshaping-layers-flatten"><strong>Reshaping Layers: Flatten</strong><a class="anchor" aria-label="anchor" href="#reshaping-layers-flatten"></a></h5>
<p>The next type of hidden layer used in our introductory model is a
type of reshaping layer defined in Keras by the
<code>tf.keras.layers.Flatten</code> class. It is necessary when
transitioning from convolutional and pooling layers to fully connected
layers.</p>
<pre><code><span><span class="co"># # Flatten layer to convert 2D feature maps into a 1D vector</span></span>
<span><span class="co"># x_intro = keras.layers.Flatten()(x_intro)</span></span></code></pre>
<p>The <strong>Flatten</strong> layer converts the output of the
previous layer into a single one-dimensional vector that can be used as
input for a dense layer.</p>
</div>
</div>
<div class="section level4">
<h4 id="cnn-part-3--output-layer">CNN Part 3. Output Layer<a class="anchor" aria-label="anchor" href="#cnn-part-3--output-layer"></a></h4>
<p>Recall for the outputs we asked ourselves what we want to identify
from the data. If we are performing a classification problem, then
typically we have one output for each potential class. We finish with a
Dense layer to connect the output cells of the convolutional layer to
the outputs for our 10 classes.</p>
<p>Note the use of <code>softmax</code> activation for this Dense layer
as opposed to the <code>ReLU</code> activation used above. We use
softmax for multiclass data because it helps the computer give each
option (class) a likelihood score, and the scores add up to 100 per
cent. This way, it’s easier to pick the one the computer thinks is most
probable.</p>
<pre><code><span><span class="co"># # Output layer with 10 units (one for each class) and softmax activation</span></span>
<span><span class="co"># outputs_intro = keras.layers.Dense(10, activation='softmax')(x_intro))</span></span></code></pre>
</div>
</div>
</section><section id="putting-it-all-together"><h2 class="section-heading">Putting it all together<a class="anchor" aria-label="anchor" href="#putting-it-all-together"></a>
</h2>
<hr class="half-width"><div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co">#### Define the Model</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="co"># CNN Part 1</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="co"># Input layer of 32x32 images with three channels (RGB)</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>inputs_intro <span class="op">=</span> keras.Input(shape<span class="op">=</span>train_images.shape[<span class="dv">1</span>:])</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co"># CNN Part 2</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co"># Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>x_intro <span class="op">=</span> keras.layers.Conv2D(<span class="dv">16</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs_intro)</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="co"># Pooling layer with input window sized 2,2</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>x_intro <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x_intro)</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="co"># Second Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>x_intro <span class="op">=</span> keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(x_intro)</span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co"># Second Pooling layer with input window sized 2,2</span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>x_intro <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x_intro)</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co"># Flatten layer to convert 2D feature maps into a 1D vector</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a>x_intro <span class="op">=</span> keras.layers.Flatten()(x_intro)</span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a><span class="co"># Dense layer with 64 neurons and ReLU activation</span></span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a>x_intro <span class="op">=</span> keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x_intro)</span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a><span class="co"># CNN Part 3</span></span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a><span class="co"># Output layer with 10 units (one for each class) and softmax activation</span></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a>outputs_intro <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x_intro)</span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a><span class="co"># create the model</span></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a>model_intro <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs_intro, outputs<span class="op">=</span>outputs_intro, name<span class="op">=</span><span class="st">"cifar_model_intro"</span>)</span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a><span class="co"># view the model summary</span></span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a>model_intro.summary()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model: "cifar_model_intro"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 32, 32, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 30, 30, 16)        448       
                                                                 
 max_pooling2d (MaxPooling2  (None, 15, 15, 16)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 13, 13, 32)        4640      
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 6, 6, 32)          0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 1152)              0         
                                                                 
 dense (Dense)               (None, 64)                73792     
                                                                 
 dense_1 (Dense)             (None, 10)                650       
                                                                 
=================================================================
Total params: 79530 (310.66 KB)
Trainable params: 79530 (310.66 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
<div id="how-to-choose-an-architecture" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="how-to-choose-an-architecture" class="callout-inner">
<h3 class="callout-title">How to choose an architecture?<a class="anchor" aria-label="anchor" href="#how-to-choose-an-architecture"></a>
</h3>
<div class="callout-content">
<p>Even for this neural network, we had to make a choice on the number
of hidden neurons. Other choices to be made are the number of layers and
type of layers. You might wonder how you should make these architectural
choices. Unfortunately, there are no clear rules to follow here, and it
often boils down to a lot of trial and error. However, it is recommended
to explore what others have done with similar datasets and problems.
Another best practice is to start with a relatively simple architecture.
Once running start to add layers and tweak the network to test if
performance increases.</p>
</div>
</div>
</div>
</section><section id="we-have-a-model-now-what"><h2 class="section-heading">We have a model now what?<a class="anchor" aria-label="anchor" href="#we-have-a-model-now-what"></a>
</h2>
<hr class="half-width"><p>This CNN should be able to run with the CIFAR-10 dataset and provide
reasonable results for basic classification tasks. However, do keep in
mind this model is relatively simple, and its performance may not be as
high as more complex architectures. The reason it’s called deep learning
is because in most cases, the more layers we have, i.e. the deeper and
more sophisticated CNN architecture we use, the better the
performance.</p>
<p>How can we tell? We can inspect a couple metrics produced during the
training process to detect whether our model is underfitting or
overfitting. To do that, we continue with the next steps in our Deep
Learning workflow, <strong>Step 5. Choose a loss function and
optimizer</strong> and <strong>Step 6. Train model</strong>.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul><li>Artificial neural networks (ANN) are a machine learning technique
based on a model inspired by groups of neurons in the brain.</li>
<li>Convolution neural networks (CNN) are a type of ANN designed for
image classification and object detection.</li>
<li>The number of filters corresponds to the number of distinct features
the layer is learning to recognise whereas the kernel size determines
the level of features being captured.</li>
<li>A CNN can consist of many types of layers including convolutional,
pooling, flatten, and dense (fully connected) layers</li>
<li>Convolutional layers are responsible for learning features from the
input data.</li>
<li>Pooling layers are often used to reduce the spatial dimensions of
the data.</li>
<li>The flatten layer is used to convert the multi-dimensional output of
the convolutional and pooling layers into a flat vector.</li>
<li>Dense layers are responsible for combining features learned by the
previous layers to perform the final classification.</li>
</ul></div>
</div>
</div>
<!-- Collect your link references at the bottom of your document -->
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/02-image-data.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/04-fit-cnn.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/02-image-data.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Introduction to
        </a>
        <a class="chapter-link float-end" href="../instructor/04-fit-cnn.html" rel="next">
          Next: Compile and Train... 
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://https://github.com/erinmgraham/icwithcnn/edit/main/episodes/03-build-cnn.html" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://https://github.com/erinmgraham/icwithcnn/blob/main/CONTRIBUTING.html" class="external-link">Contributing</a>
        | <a href="https://https://github.com/erinmgraham/icwithcnn/" class="external-link">Source</a></p>
				<p><a href="https://https://github.com/erinmgraham/icwithcnn/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:erin.graham@jcu.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.3" class="external-link">sandpaper (0.16.3)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.4" class="external-link">pegboard (0.7.4)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://.github.io/github.com/instructor/03-build-cnn.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Build a Convolutional Neural Network",
  "creativeWorkStatus": "active",
  "url": "https://.github.io/github.com/instructor/03-build-cnn.html",
  "identifier": "https://.github.io/github.com/instructor/03-build-cnn.html",
  "dateCreated": "2023-05-03",
  "dateModified": "2024-02-25",
  "datePublished": "2024-03-19"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code --></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

